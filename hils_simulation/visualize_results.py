"""
Interactive HILS Simulation Results Viewer

marimoãƒ™ãƒ¼ã‚¹ã®å¯¾è©±çš„ãªçµæœå¯è¦–åŒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‚
è¤‡æ•°ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’é¸æŠã—ã¦æ¯”è¼ƒã§ãã‚‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    cd /home/akira/mosaik-hils
    marimo edit hils_simulation/visualize_results.py
"""

import marimo

__generated_with = "0.17.0"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    return (mo,)


@app.cell
def _():
    import json
    import os
    from pathlib import Path

    import h5py
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    return Path, h5py, json, np, os, plt


@app.cell
def _(Path, json, os):
    """çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¹ã‚­ãƒ£ãƒ³"""

    # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«ãƒ‘ã‚¹ã‚’è¨­å®š
    cwd = Path(os.getcwd())

    # hils_simulationãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ã™
    if cwd.name == "hils_simulation":
        base_dir = cwd
    elif (cwd / "hils_simulation").exists():
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰å®Ÿè¡Œã•ã‚ŒãŸå ´åˆ
        base_dir = cwd / "hils_simulation"
    else:
        # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
        base_dir = cwd.parent / "hils_simulation" if cwd.parent.name != cwd.name else cwd

    all_results = []

    # 3ã¤ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³
    for dir_type, dir_name in [
        ("HILS", "results"),
        ("RT", "results_rt"),
        ("Pure", "results_pure"),
    ]:
        result_dir = base_dir / dir_name
        if not result_dir.exists():
            continue

        for subdir in sorted(result_dir.iterdir(), reverse=True):
            if not subdir.is_dir():
                continue

            h5_file = subdir / "hils_data.h5"
            if not h5_file.exists():
                continue

            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            config_file = subdir / "simulation_config.json"
            config = {}
            if config_file.exists():
                with open(config_file, "r") as f:
                    config = json.load(f)

            # é…å»¶æƒ…å ±
            comm = config.get("communication", {})
            cmd_delay = comm.get("cmd_delay_s", 0) * 1000
            sense_delay = comm.get("sense_delay_s", 0) * 1000

            if cmd_delay == 0 and sense_delay == 0:
                delay_info = "No delay"
            else:
                delay_info = f"Cmd:{cmd_delay:.0f}ms, Sense:{sense_delay:.0f}ms"

            label = f"[{dir_type}] {subdir.name} ({delay_info})"

            all_results.append(
                {
                    "type": dir_type,
                    "name": subdir.name,
                    "h5_file": str(h5_file),
                    "config": config,
                    "label": label,
                }
            )
    return all_results, base_dir


@app.cell
def _(all_results, base_dir, mo):
    """ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º"""
    if not all_results:
        title = mo.md(
            f"""
    âš ï¸ **No results found**

    Base directory: `{base_dir}`

    Check these directories:
    - `{base_dir}/results/`
    - `{base_dir}/results_rt/`
    - `{base_dir}/results_pure/`
    """
        )
    else:
        result_list_md = "\n".join([f"- {r['label']}" for r in all_results[:5]])
        more_md = f"\n- ... and {len(all_results) - 5} more" if len(all_results) > 5 else ""

        title = mo.md(
            f"""
    # HILS Simulation Results Viewer

    Found **{len(all_results)}** simulation results

    _Base directory: `{base_dir}`_

    **Available results:**
    {result_list_md}{more_md}

    ---

    **Select up to 3 results to compare:**
    """
        )
    return (title,)


@app.cell
def _(title):
    """ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º"""
    title
    return


@app.cell
def _(all_results, mo):
    """ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ä½œæˆ"""
    if len(all_results) == 0:
        dd1 = None
        dd2 = None
        dd3 = None
        dd_ui = None
    else:
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ãƒ©ãƒ™ãƒ« -> ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        opts = {r["label"]: i for i, r in enumerate(all_results)}

        # æœ€åˆã¨2ç•ªç›®ã®ãƒ©ãƒ™ãƒ«ã‚’å–å¾—
        labels = list(opts.keys())
        first_label = labels[0] if len(labels) > 0 else None
        second_label = labels[1] if len(labels) > 1 else "(None)"

        dd1 = mo.ui.dropdown(opts, value=first_label, label="ğŸ“Š Result 1")

        dd2 = mo.ui.dropdown({**{"(None)": -1}, **opts}, value=second_label, label="ğŸ“Š Result 2")

        dd3 = mo.ui.dropdown({**{"(None)": -1}, **opts}, value="(None)", label="ğŸ“Š Result 3")

        dd_ui = mo.vstack([dd1, dd2, dd3])
    return dd1, dd2, dd3, dd_ui


@app.cell
def _(dd_ui):
    """ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³è¡¨ç¤º"""
    dd_ui
    return


@app.cell
def _(all_results, dd1, dd2, dd3):
    """é¸æŠã•ã‚ŒãŸçµæœã®å–å¾—"""
    selected_results = []
    if len(all_results) > 0 and dd1 is not None:
        for dd in [dd1, dd2, dd3]:
            if dd is not None and dd.value is not None:
                idx = dd.value
                if isinstance(idx, int) and idx >= 0 and idx < len(all_results):
                    selected_results.append(all_results[idx])
    return (selected_results,)


@app.cell
def _(np):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–¢æ•°"""

    def calculate_detailed_metrics(
        time: np.ndarray,
        position: np.ndarray,
        velocity: np.ndarray,
        error: np.ndarray,
        thrust: np.ndarray,
        target_position: float,
    ):
        """
        è©³ç´°ãªåˆ¶å¾¡æ€§èƒ½æŒ‡æ¨™ã‚’è¨ˆç®—

        Returns:
            Dict with performance metrics
        """
        metrics = {}

        # åŸºæœ¬çµ±è¨ˆ
        metrics["rms_error"] = np.sqrt(np.mean(error**2))
        metrics["max_error"] = np.max(np.abs(error))
        metrics["mean_abs_error"] = np.mean(np.abs(error))
        metrics["std_error"] = np.std(error)

        # ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ¥ãƒ¼ãƒˆ
        overshoot = np.max(position) - target_position
        metrics["overshoot"] = overshoot
        metrics["overshoot_percent"] = (
            (overshoot / target_position) * 100 if target_position != 0 else 0
        )

        # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚·ãƒ¥ãƒ¼ãƒˆ
        undershoot = target_position - np.min(position)
        metrics["undershoot"] = undershoot
        metrics["undershoot_percent"] = (
            (undershoot / target_position) * 100 if target_position != 0 else 0
        )

        # æ•´å®šæ™‚é–“ï¼ˆèª¤å·®ãŒ5%ä»¥å†…ã«åã¾ã‚‹æ™‚åˆ»ï¼‰
        settling_threshold = 0.05 * abs(target_position)
        settled_indices = np.where(np.abs(error) <= settling_threshold)[0]
        if len(settled_indices) > 0:
            for idx in settled_indices:
                if np.all(np.abs(error[idx:]) <= settling_threshold):
                    metrics["settling_time_5pct"] = time[idx]
                    break
            else:
                metrics["settling_time_5pct"] = None
        else:
            metrics["settling_time_5pct"] = None

        # æ•´å®šæ™‚é–“ï¼ˆ2%åŸºæº–ï¼‰
        settling_threshold_2 = 0.02 * abs(target_position)
        settled_indices_2 = np.where(np.abs(error) <= settling_threshold_2)[0]
        if len(settled_indices_2) > 0:
            for idx in settled_indices_2:
                if np.all(np.abs(error[idx:]) <= settling_threshold_2):
                    metrics["settling_time_2pct"] = time[idx]
                    break
            else:
                metrics["settling_time_2pct"] = None
        else:
            metrics["settling_time_2pct"] = None

        # æœ€çµ‚èª¤å·®ï¼ˆæœ€å¾Œã®10%ã®å¹³å‡ï¼‰
        final_window = max(int(len(error) * 0.1), 1)
        metrics["final_error"] = np.mean(np.abs(error[-final_window:]))
        metrics["final_std"] = np.std(error[-final_window:])

        # ç«‹ã¡ä¸ŠãŒã‚Šæ™‚é–“ï¼ˆç›®æ¨™ã®10%ã‹ã‚‰90%ã«åˆ°é”ã™ã‚‹æ™‚é–“ï¼‰
        pos_10pct = 0.1 * target_position
        pos_90pct = 0.9 * target_position
        idx_10 = np.where(position >= pos_10pct)[0]
        idx_90 = np.where(position >= pos_90pct)[0]
        if len(idx_10) > 0 and len(idx_90) > 0:
            metrics["rise_time"] = time[idx_90[0]] - time[idx_10[0]]
        else:
            metrics["rise_time"] = None

        # ãƒ”ãƒ¼ã‚¯æ™‚é–“
        peak_idx = np.argmax(position)
        metrics["peak_time"] = time[peak_idx]
        metrics["peak_value"] = position[peak_idx]

        # åˆ¶å¾¡å…¥åŠ›ã®çµ±è¨ˆ
        metrics["mean_thrust"] = np.mean(np.abs(thrust))
        metrics["max_thrust"] = np.max(np.abs(thrust))
        metrics["thrust_variation"] = np.std(thrust)

        # åˆ¶å¾¡å…¥åŠ›ã®ç·å¤‰åŒ–é‡ï¼ˆTotal Variationï¼‰
        if len(thrust) > 1:
            metrics["control_effort"] = np.sum(np.abs(np.diff(thrust)))
        else:
            metrics["control_effort"] = 0

        # é€Ÿåº¦ã®çµ±è¨ˆ
        metrics["max_velocity"] = np.max(np.abs(velocity))
        metrics["final_velocity"] = np.mean(np.abs(velocity[-final_window:]))

        # ISE (Integral of Squared Error)
        if len(time) > 1:
            dt = time[1] - time[0]
            metrics["ise"] = np.sum(error**2) * dt
        else:
            metrics["ise"] = 0

        # IAE (Integral of Absolute Error)
        if len(time) > 1:
            dt = time[1] - time[0]
            metrics["iae"] = np.sum(np.abs(error)) * dt
        else:
            metrics["iae"] = 0

        # ITAE (Integral of Time-weighted Absolute Error)
        if len(time) > 1:
            dt = time[1] - time[0]
            metrics["itae"] = np.sum(time * np.abs(error)) * dt
        else:
            metrics["itae"] = 0

        return metrics

    return (calculate_detailed_metrics,)


@app.cell
def _(calculate_detailed_metrics, h5py, mo, np, plt, selected_results):
    """ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""

    def load_hdf5_data(h5_path):
        """HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        hdf5_data = {}
        with h5py.File(h5_path, "r") as f:
            if "data" in f:
                for key in f["data"].keys():
                    hdf5_data[key] = f["data"][key][:]
            else:
                for key in f.keys():
                    if isinstance(f[key], h5py.Dataset):
                        hdf5_data[key] = f[key][:]
        return hdf5_data

    def find_key_by_suffix(key_data, suffix):
        """ã‚­ãƒ¼ã®æ¥å°¾è¾ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚­ãƒ¼ã‚’æ¤œç´¢"""
        for k in key_data.keys():
            if k.endswith(suffix):
                return k
        return None

    def find_key_by_prefix_and_suffix(key_data, prefix, suffix):
        """ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¨ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚­ãƒ¼ã‚’æ¤œç´¢"""
        for k in key_data.keys():
            if k.startswith(prefix) and k.endswith(suffix):
                return k
        return None

    def generate_comparison_plot_and_metrics(results_list):
        """æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""

        if len(results_list) == 0:
            return mo.md("âš ï¸ Please select at least one result"), []

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
        all_metrics = []

        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, axes = plt.subplots(4, 1, figsize=(14, 16))
        colors = ["#1f77b4", "#ff7f0e", "#2ca02c"]
        styles = ["-", "--", ":"]

        for plot_idx, result_item in enumerate(results_list):
            try:
                result_data = load_hdf5_data(result_item["h5_file"])
                time_data = result_data.get("time_s", np.array([]))

                # ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ã®æ¤œç´¢ï¼ˆcompare_all.py ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰

                # HILS/RT ã®å ´åˆ: position_EnvSim-0.Spacecraft1DOF_0
                result_pos_key = find_key_by_prefix_and_suffix(
                    result_data, "position_", "Spacecraft1DOF_0"
                )

                # Pure Python ã®å ´åˆ: position_Spacecraft
                if not result_pos_key:
                    result_pos_key = find_key_by_suffix(result_data, "position_Spacecraft")

                if not result_pos_key:
                    print(f"âš ï¸ Warning: Could not find position key for {result_item['name']}")
                    print(f"   Available keys: {list(result_data.keys())[:10]}")
                    continue

                # Velocity: position ã‚’ velocity ã«ç½®ãæ›ãˆ
                result_vel_key = result_pos_key.replace("position", "velocity")

                # Thrust: command_..._thrust (compare_all.py ã¨åŒã˜)
                result_thrust_key = find_key_by_suffix(result_data, "_thrust")

                # Error: error_..._Controller...
                result_error_key = find_key_by_prefix_and_suffix(
                    result_data, "error_", "Controller_0"
                )
                if not result_error_key:
                    result_error_key = find_key_by_suffix(result_data, "error_Controller")

                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                result_position = result_data.get(result_pos_key, np.array([]))
                result_velocity = result_data.get(result_vel_key, np.array([]))
                result_thrust = result_data.get(result_thrust_key, np.array([]))
                result_error = result_data.get(result_error_key, np.array([]))

                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                print(f"\n{result_item['name']}:")
                print(f"  pos_key: {result_pos_key} (len={len(result_position)})")
                print(f"  vel_key: {result_vel_key} (len={len(result_velocity)})")
                print(f"  thrust_key: {result_thrust_key} (len={len(result_thrust)})")
                print(f"  error_key: {result_error_key} (len={len(result_error)})")

                # ç›®æ¨™ä½ç½®ã®å–å¾—
                target_position = result_item["config"].get("control", {}).get(
                    "target_position_m", 5.0
                )

                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                if (
                    len(time_data) > 0
                    and len(result_position) > 0
                    and len(result_velocity) > 0
                    and len(result_error) > 0
                    and len(result_thrust) > 0
                ):
                    metrics = calculate_detailed_metrics(
                        time_data,
                        result_position,
                        result_velocity,
                        result_error,
                        result_thrust,
                        target_position,
                    )
                    all_metrics.append(
                        {
                            "name": result_item["name"],
                            "label": result_item["label"],
                            "type": result_item["type"],
                            "metrics": metrics,
                        }
                    )

                result_label = result_item["label"]
                result_color = colors[plot_idx % len(colors)]
                result_style = styles[plot_idx % len(styles)]

                # ãƒ—ãƒ­ãƒƒãƒˆ
                if len(result_position) > 0:
                    axes[0].plot(
                        time_data,
                        result_position,
                        color=result_color,
                        ls=result_style,
                        label=result_label,
                        lw=1.5,
                        alpha=0.8,
                    )
                else:
                    print(f"  âš ï¸ No position data")

                if len(result_velocity) > 0:
                    axes[1].plot(
                        time_data,
                        result_velocity,
                        color=result_color,
                        ls=result_style,
                        label=result_label,
                        lw=1.5,
                        alpha=0.8,
                    )
                else:
                    print(f"  âš ï¸ No velocity data")

                if len(result_thrust) > 0:
                    axes[2].plot(
                        time_data,
                        result_thrust,
                        color=result_color,
                        ls=result_style,
                        label=result_label,
                        lw=1.5,
                        alpha=0.8,
                    )
                else:
                    print(f"  âš ï¸ No thrust data")

                if len(result_error) > 0:
                    axes[3].plot(
                        time_data,
                        result_error,
                        color=result_color,
                        ls=result_style,
                        label=result_label,
                        lw=1.5,
                        alpha=0.8,
                    )
                else:
                    print(f"  âš ï¸ No error data")

            except Exception as exc:
                import traceback

                print(f"\nâŒ Error loading {result_item['name']}:")
                print(f"  {exc}")
                print(traceback.format_exc())

        # è»¸è¨­å®š
        plot_target = 5.0
        if len(results_list) > 0:
            plot_target = results_list[0]["config"].get("control", {}).get("target_position_m", 5.0)

        axes[0].axhline(plot_target, color="k", linestyle=":", label="Target", lw=1)
        axes[0].set_ylabel("Position [m]", fontsize=11)
        axes[0].set_title("Position Comparison", fontsize=13, fontweight="bold")
        axes[0].legend(fontsize=9, loc="best")
        axes[0].grid(True, alpha=0.3)

        axes[1].set_ylabel("Velocity [m/s]", fontsize=11)
        axes[1].set_title("Velocity Comparison", fontsize=13, fontweight="bold")
        axes[1].legend(fontsize=9, loc="best")
        axes[1].grid(True, alpha=0.3)

        axes[2].set_ylabel("Thrust [N]", fontsize=11)
        axes[2].set_title("Control Input Comparison", fontsize=13, fontweight="bold")
        axes[2].legend(fontsize=9, loc="best")
        axes[2].grid(True, alpha=0.3)

        axes[3].set_xlabel("Time [s]", fontsize=11)
        axes[3].set_ylabel("Position Error [m]", fontsize=11)
        axes[3].set_title("Control Error Comparison", fontsize=13, fontweight="bold")
        axes[3].axhline(0, color="k", linestyle=":", lw=1)
        axes[3].legend(fontsize=9, loc="best")
        axes[3].grid(True, alpha=0.3)

        plt.tight_layout()
        return fig, all_metrics

    # é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç”Ÿæˆ
    plot_fig, computed_metrics = generate_comparison_plot_and_metrics(selected_results)
    return computed_metrics, plot_fig


@app.cell
def _(plot_fig):
    """ãƒ—ãƒ­ãƒƒãƒˆè¡¨ç¤º"""
    plot_fig
    return


@app.cell
def _(computed_metrics, mo, pd):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º"""

    if not computed_metrics or len(computed_metrics) == 0:
        metrics_display = mo.md("_No metrics available. Please select at least one result._")
        error_table = None
        transient_table = None
        integral_table = None
        control_table = None
        relative_table = None
    else:
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’DataFrameã«å¤‰æ›ï¼ˆæ•°å€¤å‹ã§ä¿æŒï¼‰
        rows = []
        for item in computed_metrics:
            metrics = item["metrics"]
            row = {
                "Simulation": item["label"],
                "Type": item["type"],
                "RMS Error": metrics["rms_error"],
                "Max Error": metrics["max_error"],
                "Mean |Error|": metrics["mean_abs_error"],
                "Std Error": metrics["std_error"],
                "Final Error": metrics["final_error"],
                "Overshoot": metrics["overshoot"],
                "Overshoot %": metrics["overshoot_percent"],
                "Rise Time": metrics["rise_time"] if metrics["rise_time"] is not None else None,
                "Settling 5%": (
                    metrics["settling_time_5pct"]
                    if metrics["settling_time_5pct"] is not None
                    else None
                ),
                "Settling 2%": (
                    metrics["settling_time_2pct"]
                    if metrics["settling_time_2pct"] is not None
                    else None
                ),
                "ISE": metrics["ise"],
                "IAE": metrics["iae"],
                "ITAE": metrics["itae"],
                "Max Thrust": metrics["max_thrust"],
                "Mean |Thrust|": metrics["mean_thrust"],
                "Control Effort": metrics["control_effort"],
                "Max Velocity": metrics["max_velocity"],
            }
            rows.append(row)

        df = pd.DataFrame(rows)

        # å„ã‚«ãƒ†ã‚´ãƒªã®è¡¨ã‚’ä½œæˆï¼ˆæ•°å€¤ã¯é©åˆ‡ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
        error_table = df[
            ["Simulation", "RMS Error", "Max Error", "Mean |Error|", "Std Error", "Final Error"]
        ].copy()
        error_table["RMS Error"] = error_table["RMS Error"].apply(lambda x: f"{x:.6f}")
        error_table["Max Error"] = error_table["Max Error"].apply(lambda x: f"{x:.6f}")
        error_table["Mean |Error|"] = error_table["Mean |Error|"].apply(lambda x: f"{x:.6f}")
        error_table["Std Error"] = error_table["Std Error"].apply(lambda x: f"{x:.6f}")
        error_table["Final Error"] = error_table["Final Error"].apply(lambda x: f"{x:.6f}")

        transient_table = df[
            ["Simulation", "Overshoot", "Overshoot %", "Rise Time", "Settling 5%", "Settling 2%"]
        ].copy()
        transient_table["Overshoot"] = transient_table["Overshoot"].apply(lambda x: f"{x:.6f}")
        transient_table["Overshoot %"] = transient_table["Overshoot %"].apply(
            lambda x: f"{x:.2f}%"
        )
        transient_table["Rise Time"] = transient_table["Rise Time"].apply(
            lambda x: f"{x:.4f}" if pd.notna(x) else "N/A"
        )
        transient_table["Settling 5%"] = transient_table["Settling 5%"].apply(
            lambda x: f"{x:.4f}" if pd.notna(x) else "N/A"
        )
        transient_table["Settling 2%"] = transient_table["Settling 2%"].apply(
            lambda x: f"{x:.4f}" if pd.notna(x) else "N/A"
        )

        integral_table = df[["Simulation", "ISE", "IAE", "ITAE"]].copy()
        integral_table["ISE"] = integral_table["ISE"].apply(lambda x: f"{x:.6f}")
        integral_table["IAE"] = integral_table["IAE"].apply(lambda x: f"{x:.6f}")
        integral_table["ITAE"] = integral_table["ITAE"].apply(lambda x: f"{x:.6f}")

        control_table = df[
            ["Simulation", "Max Thrust", "Mean |Thrust|", "Control Effort", "Max Velocity"]
        ].copy()
        control_table["Max Thrust"] = control_table["Max Thrust"].apply(lambda x: f"{x:.4f}")
        control_table["Mean |Thrust|"] = control_table["Mean |Thrust|"].apply(
            lambda x: f"{x:.4f}"
        )
        control_table["Control Effort"] = control_table["Control Effort"].apply(
            lambda x: f"{x:.4f}"
        )
        control_table["Max Velocity"] = control_table["Max Velocity"].apply(lambda x: f"{x:.6f}")

        # ç›¸å¯¾æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ‹¡å……ç‰ˆï¼‰
        if len(computed_metrics) >= 2:
            ref_metrics = computed_metrics[0]["metrics"]

            # èª¤å·®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¯”è¼ƒ
            error_rel_rows = []
            for item in computed_metrics[1:]:
                comp_metrics = item["metrics"]
                rel_row = {"Simulation": item["label"]}

                # RMS Error
                if ref_metrics["rms_error"] != 0:
                    rel_row["RMS Error Î”%"] = f"{((comp_metrics['rms_error'] - ref_metrics['rms_error']) / ref_metrics['rms_error'] * 100):+.2f}%"
                else:
                    rel_row["RMS Error Î”%"] = "N/A"

                # Max Error
                if ref_metrics["max_error"] != 0:
                    rel_row["Max Error Î”%"] = f"{((comp_metrics['max_error'] - ref_metrics['max_error']) / ref_metrics['max_error'] * 100):+.2f}%"
                else:
                    rel_row["Max Error Î”%"] = "N/A"

                # Mean Abs Error
                if ref_metrics["mean_abs_error"] != 0:
                    rel_row["Mean |Error| Î”%"] = f"{((comp_metrics['mean_abs_error'] - ref_metrics['mean_abs_error']) / ref_metrics['mean_abs_error'] * 100):+.2f}%"
                else:
                    rel_row["Mean |Error| Î”%"] = "N/A"

                # Final Error
                if ref_metrics["final_error"] != 0:
                    rel_row["Final Error Î”%"] = f"{((comp_metrics['final_error'] - ref_metrics['final_error']) / ref_metrics['final_error'] * 100):+.2f}%"
                else:
                    rel_row["Final Error Î”%"] = "N/A"

                error_rel_rows.append(rel_row)

            error_relative_table = pd.DataFrame(error_rel_rows) if error_rel_rows else None

            # éæ¸¡å¿œç­”ã®æ¯”è¼ƒ
            transient_rel_rows = []
            for item in computed_metrics[1:]:
                comp_metrics = item["metrics"]
                rel_row = {"Simulation": item["label"]}

                # Overshoot
                if ref_metrics["overshoot"] != 0:
                    rel_row["Overshoot Î”%"] = f"{((comp_metrics['overshoot'] - ref_metrics['overshoot']) / ref_metrics['overshoot'] * 100):+.2f}%"
                else:
                    rel_row["Overshoot Î”%"] = "N/A"

                # Rise Time
                if ref_metrics["rise_time"] is not None and comp_metrics["rise_time"] is not None and ref_metrics["rise_time"] != 0:
                    rel_row["Rise Time Î”%"] = f"{((comp_metrics['rise_time'] - ref_metrics['rise_time']) / ref_metrics['rise_time'] * 100):+.2f}%"
                else:
                    rel_row["Rise Time Î”%"] = "N/A"

                # Settling 5%
                if ref_metrics["settling_time_5pct"] is not None and comp_metrics["settling_time_5pct"] is not None and ref_metrics["settling_time_5pct"] != 0:
                    rel_row["Settling 5% Î”%"] = f"{((comp_metrics['settling_time_5pct'] - ref_metrics['settling_time_5pct']) / ref_metrics['settling_time_5pct'] * 100):+.2f}%"
                else:
                    rel_row["Settling 5% Î”%"] = "N/A"

                # Settling 2%
                if ref_metrics["settling_time_2pct"] is not None and comp_metrics["settling_time_2pct"] is not None and ref_metrics["settling_time_2pct"] != 0:
                    rel_row["Settling 2% Î”%"] = f"{((comp_metrics['settling_time_2pct'] - ref_metrics['settling_time_2pct']) / ref_metrics['settling_time_2pct'] * 100):+.2f}%"
                else:
                    rel_row["Settling 2% Î”%"] = "N/A"

                transient_rel_rows.append(rel_row)

            transient_relative_table = pd.DataFrame(transient_rel_rows) if transient_rel_rows else None

            # ç©åˆ†æ€§èƒ½æŒ‡æ¨™ã®æ¯”è¼ƒ
            integral_rel_rows = []
            for item in computed_metrics[1:]:
                comp_metrics = item["metrics"]
                rel_row = {"Simulation": item["label"]}

                # ISE
                if ref_metrics["ise"] != 0:
                    rel_row["ISE Î”%"] = f"{((comp_metrics['ise'] - ref_metrics['ise']) / ref_metrics['ise'] * 100):+.2f}%"
                else:
                    rel_row["ISE Î”%"] = "N/A"

                # IAE
                if ref_metrics["iae"] != 0:
                    rel_row["IAE Î”%"] = f"{((comp_metrics['iae'] - ref_metrics['iae']) / ref_metrics['iae'] * 100):+.2f}%"
                else:
                    rel_row["IAE Î”%"] = "N/A"

                # ITAE
                if ref_metrics["itae"] != 0:
                    rel_row["ITAE Î”%"] = f"{((comp_metrics['itae'] - ref_metrics['itae']) / ref_metrics['itae'] * 100):+.2f}%"
                else:
                    rel_row["ITAE Î”%"] = "N/A"

                integral_rel_rows.append(rel_row)

            integral_relative_table = pd.DataFrame(integral_rel_rows) if integral_rel_rows else None

            # åˆ¶å¾¡å…¥åŠ›ã®æ¯”è¼ƒ
            control_rel_rows = []
            for item in computed_metrics[1:]:
                comp_metrics = item["metrics"]
                rel_row = {"Simulation": item["label"]}

                # Max Thrust
                if ref_metrics["max_thrust"] != 0:
                    rel_row["Max Thrust Î”%"] = f"{((comp_metrics['max_thrust'] - ref_metrics['max_thrust']) / ref_metrics['max_thrust'] * 100):+.2f}%"
                else:
                    rel_row["Max Thrust Î”%"] = "N/A"

                # Mean Thrust
                if ref_metrics["mean_thrust"] != 0:
                    rel_row["Mean |Thrust| Î”%"] = f"{((comp_metrics['mean_thrust'] - ref_metrics['mean_thrust']) / ref_metrics['mean_thrust'] * 100):+.2f}%"
                else:
                    rel_row["Mean |Thrust| Î”%"] = "N/A"

                # Control Effort
                if ref_metrics["control_effort"] != 0:
                    rel_row["Control Effort Î”%"] = f"{((comp_metrics['control_effort'] - ref_metrics['control_effort']) / ref_metrics['control_effort'] * 100):+.2f}%"
                else:
                    rel_row["Control Effort Î”%"] = "N/A"

                # Max Velocity
                if ref_metrics["max_velocity"] != 0:
                    rel_row["Max Velocity Î”%"] = f"{((comp_metrics['max_velocity'] - ref_metrics['max_velocity']) / ref_metrics['max_velocity'] * 100):+.2f}%"
                else:
                    rel_row["Max Velocity Î”%"] = "N/A"

                control_rel_rows.append(rel_row)

            control_relative_table = pd.DataFrame(control_rel_rows) if control_rel_rows else None

            # çµ±åˆç”¨ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰
            relative_table = error_relative_table
        else:
            error_relative_table = None
            transient_relative_table = None
            integral_relative_table = None
            control_relative_table = None
            relative_table = None

        metrics_display = mo.md(
            f"""
## ğŸ“Š Performance Metrics Comparison

**Total simulations compared:** {len(computed_metrics)}
        """
        )

    return (
        control_relative_table,
        control_table,
        error_relative_table,
        error_table,
        integral_relative_table,
        integral_table,
        metrics_display,
        relative_table,
        transient_relative_table,
        transient_table,
    )


@app.cell
def _(metrics_display):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º"""
    metrics_display
    return


@app.cell
def _(error_table, mo):
    """èª¤å·®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«"""
    if error_table is not None:
        error_section = mo.vstack(
            [
                mo.md("### ğŸ“‰ Error Metrics"),
                mo.ui.table(error_table, selection=None),
            ]
        )
    else:
        error_section = None
    return (error_section,)


@app.cell
def _(error_section):
    """èª¤å·®ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º"""
    error_section
    return


@app.cell
def _(mo, transient_table):
    """éæ¸¡å¿œç­”ãƒ†ãƒ¼ãƒ–ãƒ«"""
    if transient_table is not None:
        transient_section = mo.vstack(
            [
                mo.md("### âš¡ Transient Response"),
                mo.ui.table(transient_table, selection=None),
            ]
        )
    else:
        transient_section = None
    return (transient_section,)


@app.cell
def _(transient_section):
    """éæ¸¡å¿œç­”ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º"""
    transient_section
    return


@app.cell
def _(integral_table, mo):
    """ç©åˆ†æ€§èƒ½æŒ‡æ¨™ãƒ†ãƒ¼ãƒ–ãƒ«"""
    if integral_table is not None:
        integral_section = mo.vstack(
            [
                mo.md("### ğŸ“ Integral Performance Indices"),
                mo.ui.table(integral_table, selection=None),
            ]
        )
    else:
        integral_section = None
    return (integral_section,)


@app.cell
def _(integral_section):
    """ç©åˆ†æ€§èƒ½æŒ‡æ¨™ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º"""
    integral_section
    return


@app.cell
def _(control_table, mo):
    """åˆ¶å¾¡å…¥åŠ›çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«"""
    if control_table is not None:
        control_section = mo.vstack(
            [
                mo.md("### ğŸ® Control Input Statistics"),
                mo.ui.table(control_table, selection=None),
            ]
        )
    else:
        control_section = None
    return (control_section,)


@app.cell
def _(control_section):
    """åˆ¶å¾¡å…¥åŠ›çµ±è¨ˆãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º"""
    control_section
    return


@app.cell
def _(
    computed_metrics,
    control_relative_table,
    error_relative_table,
    integral_relative_table,
    mo,
    transient_relative_table,
):
    """ç›¸å¯¾æ¯”è¼ƒãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ‹¡å……ç‰ˆï¼‰"""
    if len(computed_metrics) >= 2:
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        relative_header = mo.md(
            f"""
---

## ğŸ” Relative Performance Analysis

**Baseline:** {computed_metrics[0]["label"]}

All percentages show the change relative to the baseline (positive = worse for errors, varies for other metrics).
        """
        )

        # èª¤å·®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç›¸å¯¾æ¯”è¼ƒ
        error_relative_section = None
        if error_relative_table is not None:
            error_relative_section = mo.vstack(
                [
                    mo.md("### ğŸ“‰ Error Metrics - Relative Change"),
                    mo.ui.table(error_relative_table, selection=None),
                ]
            )

        # éæ¸¡å¿œç­”ã®ç›¸å¯¾æ¯”è¼ƒ
        transient_relative_section = None
        if transient_relative_table is not None:
            transient_relative_section = mo.vstack(
                [
                    mo.md("### âš¡ Transient Response - Relative Change"),
                    mo.ui.table(transient_relative_table, selection=None),
                ]
            )

        # ç©åˆ†æ€§èƒ½æŒ‡æ¨™ã®ç›¸å¯¾æ¯”è¼ƒ
        integral_relative_section = None
        if integral_relative_table is not None:
            integral_relative_section = mo.vstack(
                [
                    mo.md("### ğŸ“ Integral Performance Indices - Relative Change"),
                    mo.ui.table(integral_relative_table, selection=None),
                ]
            )

        # åˆ¶å¾¡å…¥åŠ›ã®ç›¸å¯¾æ¯”è¼ƒ
        control_relative_section = None
        if control_relative_table is not None:
            control_relative_section = mo.vstack(
                [
                    mo.md("### ğŸ® Control Input Statistics - Relative Change"),
                    mo.ui.table(control_relative_table, selection=None),
                ]
            )
    else:
        relative_header = None
        error_relative_section = None
        transient_relative_section = None
        integral_relative_section = None
        control_relative_section = None

    return (
        control_relative_section,
        error_relative_section,
        integral_relative_section,
        relative_header,
        transient_relative_section,
    )


@app.cell
def _(relative_header):
    """ç›¸å¯¾æ¯”è¼ƒãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º"""
    relative_header
    return


@app.cell
def _(error_relative_section):
    """èª¤å·®ç›¸å¯¾æ¯”è¼ƒè¡¨ç¤º"""
    error_relative_section
    return


@app.cell
def _(transient_relative_section):
    """éæ¸¡å¿œç­”ç›¸å¯¾æ¯”è¼ƒè¡¨ç¤º"""
    transient_relative_section
    return


@app.cell
def _(integral_relative_section):
    """ç©åˆ†æ€§èƒ½ç›¸å¯¾æ¯”è¼ƒè¡¨ç¤º"""
    integral_relative_section
    return


@app.cell
def _(control_relative_section):
    """åˆ¶å¾¡å…¥åŠ›ç›¸å¯¾æ¯”è¼ƒè¡¨ç¤º"""
    control_relative_section
    return


@app.cell
def _(mo):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å®šç¾©"""
    definitions = mo.md(
        """
---

### ğŸ“– Metric Definitions

- **RMS Error**: Root Mean Square error - overall accuracy measure
- **Max Error**: Maximum absolute deviation from target
- **Mean |Error|**: Average absolute error magnitude
- **Std Error**: Standard deviation of position error
- **Final Error**: Average error in last 10% of simulation
- **Overshoot**: Maximum position beyond target
- **Rise Time**: Time from 10% to 90% of target position
- **Settling Time (5%)**: Time to stay within 5% of target permanently
- **Settling Time (2%)**: Time to stay within 2% of target permanently
- **ISE**: Integral of Squared Error - penalizes large errors
- **IAE**: Integral of Absolute Error - total error magnitude
- **ITAE**: Integral of Time-weighted Absolute Error - penalizes persistent errors
- **Control Effort**: Total variation of control input (sum of absolute changes)
- **Max Thrust**: Maximum control input magnitude
- **Mean |Thrust|**: Average control input magnitude
- **Max Velocity**: Maximum velocity during trajectory
        """
    )
    return (definitions,)


@app.cell
def _(definitions):
    """å®šç¾©è¡¨ç¤º"""
    definitions
    return


if __name__ == "__main__":
    app.run()
